# -*- coding: utf-8 -*-
"""google_OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oI2N2QEUtTDwu_PBfmf087J-bBXkd2rW
"""

!pip install google-cloud-vision

import torch

# 1. CUDA 디바이스 설정
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = ""

!unzip -q new.zip -d /content

from google.cloud import vision
import io
import os
import json
import random

client = vision.ImageAnnotatorClient()

IMAGE_DIR = "/content/new"
VALID_EXT = (".jpg", ".jpeg", ".png")

# 이미지 리스트 수집
image_paths = [
    os.path.join(IMAGE_DIR, f)
    for f in os.listdir(IMAGE_DIR)
    if f.lower().endswith(VALID_EXT)
]

print("전체 이미지 수:", len(image_paths))

# 100장 선택 (100장 미만이면 전부 사용)
sample_size = min(100, len(image_paths))
image_paths = random.sample(image_paths, sample_size)

results = []

for idx, path in enumerate(image_paths):

    try:
        with io.open(path, "rb") as image_file:
            content = image_file.read()

        image = vision.Image(content=content)
        response = client.text_detection(image=image)

        texts = response.text_annotations

        results.append({
            "image_name": os.path.basename(path),
            "full_text": texts[0].description if texts else ""
        })

        print(f"[{idx+1}/{sample_size}] 완료:", os.path.basename(path))

    except Exception as e:
        print("에러 발생:", path, e)

print("처리 완료:", len(results))

# JSON 저장
with open("/content/vision_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=4)

print("vision_results.json 저장 완료")

import json

with open("vision_results.json", "r", encoding="utf-8") as f:
    all_ocr_results = json.load(f)

print("불러온 OCR 결과 수:", len(all_ocr_results))

import json

with open("vision_results.json", "r", encoding="utf-8") as f:
    data = json.load(f)

print(data[0])

import re
from datetime import datetime

def get_lines_from_vision(ocr_result):
    """
    vision_results.json 구조에서 텍스트 라인만 추출
    """
    full_text = ocr_result["full_text"]
    lines = [l.strip() for l in full_text.split("\n") if l.strip()]
    return lines

def extract_store_name(lines):
    # ---------------------------
    # 1단계: 키워드 기반 추출
    # ---------------------------
    store_patterns = [
        r"주문\s*매장[:：]?\s*(.+)",
        r"상호[:：]?\s*(.+)",
        r"매장명[:：]?\s*(.+)",
        r"가맹점[:：]?\s*(.+)",
    ]

    for text in lines:
        for p in store_patterns:
            m = re.search(p, text)
            if m:
                name = m.group(1).strip()
                if len(name) > 1:
                    return name

    # ---------------------------
    # 2단계: 상단 추론 방식
    # ---------------------------
    STORE_KEYWORDS = [
        "점", "마트", "상회", "스토어", "편의점",
        "카페", "커피", "식당", "분식", "치킨", "버거"
    ]

    BLOCK_KEYWORDS = [
        "사업자", "TEL", "전화", "합계", "총액",
        "카드", "단가", "수량", "금액", "상품",
        "고객용", "주문", "요청", "주소"
    ]

    candidates = lines[:10]

    best_score = -999
    best_text = ""

    for text in candidates:
        score = 0

        if re.search(r"[가-힣]", text):
            score += 2

        if not re.search(r"\d", text):
            score += 1

        if 2 <= len(text) <= 20:
            score += 1

        if any(k in text for k in STORE_KEYWORDS):
            score += 2

        if any(k in text for k in BLOCK_KEYWORDS):
            score -= 5

        if score > best_score:
            best_score = score
            best_text = text

    return best_text

def extract_date(lines):
    date_patterns = [
        r"(20\d{2})[-./년\s]*(\d{1,2})[-./월\s]*(\d{1,2})",
    ]

    for text in lines:
        for pattern in date_patterns:
            m = re.search(pattern, text)
            if m:
                y, mth, d = m.groups()
                try:
                    dt = datetime(int(y), int(mth), int(d))
                    return dt.strftime("%Y-%m-%d")
                except:
                    continue
    return ""

TOTAL_KEYWORDS = ["합계", "총액", "결제금액", "판매금액"]

def extract_total(lines):
    # 1차: 합계 키워드 기반
    for i, text in enumerate(lines):
        if any(k in text for k in TOTAL_KEYWORDS):
            nums = re.findall(r"\d{1,3}(?:,\d{3})+", text)
            if nums:
                return int(nums[-1].replace(",", ""))

            if i + 1 < len(lines):
                nums = re.findall(r"\d{1,3}(?:,\d{3})+", lines[i+1])
                if nums:
                    return int(nums[-1].replace(",", ""))

    # 2차: 전체 금액 중 최대값
    all_nums = []
    for text in lines:
        nums = re.findall(r"\d{1,3}(?:,\d{3})+", text)
        for n in nums:
            all_nums.append(int(n.replace(",", "")))

    if all_nums:
        return max(all_nums)

    return 0

def extract_payment(lines):
    for text in lines:
        if "카드" in text:
            return "card"
        if "현금" in text:
            return "cash"
        if "페이" in text:
            return "app"
    return ""

def build_db_json(ocr_result):
    lines = ocr_result["full_text"].split("\n")

    store = extract_store_name(lines)
    date = extract_date(lines)
    total = extract_total(lines)
    payment = extract_payment(lines)

    category = classify_category(store, ocr_result["full_text"])

    return {
        "user_id": 1,
        "image_path": ocr_result["image_name"],
        "category": category,
        "date": date,
        "total": total,
        "store_name": store,
        "payment": payment,
        "details": {
            "items": [],
            "tax": "",
            "discount": 0,
            "card_number": "",
            "address": "",
            "tel": ""
        }
    }

#카테고리 분류(식비 | 카페 | 교통 | 쇼핑 | 의료 | 편의점 | 주유 | 기타)

CATEGORY_RULES = {
    "식비": ["식당", "김밥", "국밥", "치킨", "피자", "버거", "쌀국수"],
    "카페": ["카페", "커피", "스타벅스", "이디야", "투썸", "메가커피"],
    "편의점": ["CU", "GS25", "세븐일레븐", "이마트24"],
    "교통": ["택시", "카카오T", "버스", "지하철", "KTX"],
    "주유": ["주유", "SK에너지", "GS칼텍스", "현대오일뱅크", "S-OIL"],
    "쇼핑": ["쿠팡", "11번가", "이마트", "홈플러스", "롯데마트", "백화점"],
    "의료": ["약국", "병원", "치과", "한의원"]
}

def classify_category(store_name, full_text):
    store_upper = store_name.upper()
    text_upper = full_text.upper()

    # 1단계: 상호명 기준 분류 (가장 강력)
    for category, keywords in CATEGORY_RULES.items():
        for kw in keywords:
            if kw.upper() in store_upper:
                return category

    # 2단계: 상단 10줄만 검사
    top_text = "\n".join(full_text.split("\n")[:10]).upper()
    for category, keywords in CATEGORY_RULES.items():
        for kw in keywords:
            if kw.upper() in top_text:
                return category

    # 3단계: 전체 텍스트 검사 (최후 수단)
    for category, keywords in CATEGORY_RULES.items():
        for kw in keywords:
            if kw.upper() in text_upper:
                return category

    return "기타"

import json

with open("vision_results.json", "r", encoding="utf-8") as f:
    all_ocr_results = json.load(f)

final_results = []

for r in all_ocr_results:
    final_results.append(build_db_json(r))

with open("receipts_for_db_final.json", "w", encoding="utf-8") as f:
    json.dump(final_results, f, ensure_ascii=False, indent=2)

print("완료:", len(final_results))
